[OSEv3:vars]

###########################################################################
### Ansible Vars
###########################################################################
timeout=60
ansible_become=yes
ansible_ssh_user=ec2-user


# disable memory check, as we are not a production environment
openshift_disable_check="memory_availability"

openshift_release=v3.7
openshift_master_cluster_hostname=loadbalancer1.0c39.internal
openshift_master_cluster_public_hostname=loadbalancer.0c39.example.opentlc.com
openshift_master_default_subdomain=apps.0c39.example.opentlc.com
openshift_metrics_install_metrics=true
openshift_logging_install_logging=true
deployment_type=openshift-enterprise
containerized=false
openshift_master_cluster_method=native

openshift_enable_service_catalog=true
template_service_broker_install=true
template_service_broker_selector={"env":"infra"}
openshift_template_service_broker_namespaces=['openshift']
ansible_service_broker_install=false

# Logging - External NFS Host
# NFS volume must already exist with path "nfs_directory/_volume_name" on
# the storage_host. For example, the remote volume path using these
# options would be "nfs.example.com:/exports/logging"
openshift_logging_storage_kind=nfs
openshift_logging_storage_access_modes=['ReadWriteOnce']
#openshift_logging_storage_host=support1.0c39.internal
openshift_logging_storage_nfs_directory=/exports
openshift_logging_storage_volume_name=logging-es
openshift_logging_storage_volume_size=10Gi
openshift_logging_storage_labels={'storage': 'logging'}

# Metrics - External NFS Host
# NFS volume must already exist with path "nfs_directory/_volume_name" on
# the storage_host. For example, the remote volume path using these
# options would be "nfs.example.com:/exports/metrics"
openshift_metrics_storage_kind=nfs
openshift_metrics_storage_access_modes=['ReadWriteOnce']
#openshift_metrics_storage_host=support1.0c39.internal
openshift_metrics_storage_nfs_directory=/exports
openshift_metrics_storage_volume_name=metrics
openshift_metrics_storage_volume_size=10Gi
openshift_metrics_storage_labels={'storage': 'metrics'}

# Registry Storage on External NFS Host
# NFS volume must already exist with path "nfs_directory/_volume_name" on
# the storage_host. For example, the remote volume path using these
# options would be "nfs.example.com:/exports/registry"
# nfs_directory must conform to DNS-1123 subdomain must consist of lower case
# alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character
openshift_hosted_registry_storage_kind=nfs
openshift_hosted_registry_storage_access_modes=['ReadWriteMany']
#openshift_hosted_registry_storage_host=support1.0c39.internal
openshift_hosted_registry_storage_nfs_directory=/exports
openshift_hosted_registry_storage_volume_name=registry
openshift_hosted_registry_storage_volume_size=10Gi

#Console auth stuff
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider', 'filename': '/etc/origin/master/htpasswd'}]
openshift_master_htpasswd_users={'justin': '$apr1$dCb5zcYj$VbbgLQOfRK0f8W3TSALDP.'}

#Infra targetting
openshift_metrics_cassandra_nodeselector={"env":"infra"}
openshift_metrics_hawkular_nodeselector={"env":"infra"}
openshift_metrics_heapster_nodeselector={"env":"infra"}

openshift_logging_es_nodeselector={"env":"infra"}
openshift_logging_kibana_nodeselector={"env":"infra"}
openshift_logging_curator_nodeselector={"env":"infra"}

openshift_hosted_router_selector='env=infra'
openshift_hosted_router_replicas=2

openshift_hosted_registry_selector='env=infra'

[OSEv3:children]
lb
masters
etcd
nodes
nfs

[lb]
loadbalancer1.0c39.internal host_zone=us-east-1e

[masters]
master2.0c39.internal host_zone=us-east-1e
master3.0c39.internal host_zone=us-east-1e
master1.0c39.internal host_zone=us-east-1e

[etcd]
master2.0c39.internal host_zone=us-east-1e
master3.0c39.internal host_zone=us-east-1e
master1.0c39.internal host_zone=us-east-1e

[nodes]
## These are the masters
master2.0c39.internal openshift_hostname=master2.0c39.internal  openshift_node_labels="{'logging':'true','openshift_schedulable':'False','cluster': '0c39', 'zone': 'us-east-1e'}"
master3.0c39.internal openshift_hostname=master3.0c39.internal  openshift_node_labels="{'logging':'true','openshift_schedulable':'False','cluster': '0c39', 'zone': 'us-east-1e'}"
master1.0c39.internal openshift_hostname=master1.0c39.internal  openshift_node_labels="{'logging':'true','openshift_schedulable':'False','cluster': '0c39', 'zone': 'us-east-1e'}"

## These are infranodes
infranode1.0c39.internal openshift_hostname=infranode1.0c39.internal  openshift_node_labels="{'logging':'true','cluster': '0c39', 'env':'infra', 'zone': 'us-east-1e'}"
infranode2.0c39.internal openshift_hostname=infranode2.0c39.internal  openshift_node_labels="{'logging':'true','cluster': '0c39', 'env':'infra', 'zone': 'us-east-1e'}"

## These are regular nodes
node1.0c39.internal openshift_hostname=node1.0c39.internal  openshift_node_labels="{'logging':'true','cluster': '0c39', 'env':'app', 'zone': 'us-east-1e'}"
node3.0c39.internal openshift_hostname=node3.0c39.internal  openshift_node_labels="{'logging':'true','cluster': '0c39', 'env':'app', 'zone': 'us-east-1e'}"
node2.0c39.internal openshift_hostname=node2.0c39.internal  openshift_node_labels="{'logging':'true','cluster': '0c39', 'env':'app', 'zone': 'us-east-1e'}"

[nfs]
support1.0c39.internal openshift_hostname=support1.0c39.internal